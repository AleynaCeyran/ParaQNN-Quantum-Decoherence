"""
Training script for ParaQNN.

This script handles the training loop, validation, checkpointing, and
data loading. It is designed to be regime-agnostic, working with any
dataset generated by the simulation scripts.
"""

import argparse
import logging
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import torch
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, Subset
from tqdm import tqdm

from src.models.paraqnn import ParaQNN
from src.training.objectives import ParaconsistentLoss
from src.utils.common import find_project_root, load_yaml, set_reproducibility

LOGGER = logging.getLogger("trainer")


@dataclass(frozen=True)
class DataKeys:
    """Standardized keys for accessing dataset tensors."""
    t: str
    ideal: str
    noisy: str
    labels: Optional[str]


class QuantumTrainer:
    """
    Trainer class for the ParaQNN model.

    Attributes:
        config_path (Path): Path to the training configuration YAML.
        config (Dict): Loaded configuration dictionary.
        device (torch.device): Compute device (CPU/GPU).
        model (ParaQNN): The neural network model.
        criterion (ParaconsistentLoss): The loss function.
        optimizer (optim.Optimizer): The optimizer.
        scheduler (Optional[Any]): The learning rate scheduler.
        seed (int): Random seed used for reproducibility and checkpoint versioning.
    """

    def __init__(self, config_path: Path, seed: Optional[int] = None):
        self.this_file = Path(__file__).resolve()
        self.project_root = find_project_root(self.this_file)

        self.config_path = config_path.resolve()
        self.config = load_yaml(self.config_path)

        # Robust device selection
        requested_device = self.config.get("experiment", {}).get("device", "cpu")
        if requested_device == "cuda" and not torch.cuda.is_available():
            LOGGER.warning("CUDA requested but not available. Falling back to CPU.")
            self.device = torch.device("cpu")
        else:
            self.device = torch.device(requested_device)

        # Seed configuration: CLI argument overrides YAML config
        config_seed = int(self.config.get("experiment", {}).get("seed", 42))
        self.seed = seed if seed is not None else config_seed
        
        set_reproducibility(self.seed, self.device)

        self.model = self._build_model().to(self.device)
        self.criterion = self._build_loss()
        self.optimizer = self._build_optimizer()
        self.scheduler = self._build_scheduler()

        self.train_loader: Optional[DataLoader] = None
        self.val_loader: Optional[DataLoader] = None

        LOGGER.info("Project root: %s", self.project_root)
        LOGGER.info("Using config: %s", self.config_path)
        LOGGER.info("Trainer initialized | device=%s | seed=%d", self.device, self.seed)

    def _build_model(self) -> ParaQNN:
        cfg = self.config["model"]
        return ParaQNN(
            input_dim=int(cfg["input_dim"]),
            hidden_dim=int(cfg.get("neurons_per_layer", 128)),
            output_dim=int(cfg["output_dim"]),
            num_layers=int(cfg.get("hidden_layers", 3)),
            initial_alpha=float(cfg.get("initial_alpha", 6.0)),
            sharpness_k=float(cfg.get("sharpness_k", 1.0)),
            f_init=str(cfg.get("f_init", "zeros")),
        )

    def _build_loss(self) -> ParaconsistentLoss:
        cfg = self.config["loss"]
        return ParaconsistentLoss(
            lambda_signal=float(cfg["lambda_signal"]),
            lambda_noise=float(cfg["lambda_noise"]),
            lambda_contradiction=float(cfg["lambda_contradiction"]),
        )

    def _build_optimizer(self) -> optim.Optimizer:
        cfg = self.config["training"]
        return optim.Adam(
            self.model.parameters(),
            lr=float(cfg["learning_rate"]),
            weight_decay=float(cfg.get("weight_decay", 0.0)),
        )

    def _build_scheduler(self) -> Optional[Any]:
        cfg = self.config.get("training", {})
        s_cfg = cfg.get("scheduler")
        if not s_cfg:
            return None

        stype = s_cfg.get("type")
        if stype == "ReduceLROnPlateau":
            return optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer,
                patience=int(s_cfg.get("patience", 50)),
                factor=float(s_cfg.get("factor", 0.5)),
            )
        if stype == "StepLR":
            return optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=int(s_cfg.get("step_size", 100)),
                gamma=float(s_cfg.get("gamma", 0.5)),
            )
        if stype == "CosineAnnealingLR":
            return optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer,
                T_max=int(s_cfg.get("T_max", 100)),
            )

        raise ValueError(f"Unknown scheduler type: {stype!r}")

    def _resolve_data_keys(self, keys: List[str]) -> DataKeys:
        """
        Heuristically resolve data keys from the NPZ file.
        Support legacy keys for backward compatibility.
        """
        # Time
        t_key = None
        for k in ["t", "time"]:
            if k in keys:
                t_key = k
                break
        if t_key is None:
            raise KeyError(f"Time key missing. Found: {sorted(keys)}")

        # Ideal Signal
        ideal_key = None
        for k in ["ideal", "signal_ideal"]:
            if k in keys:
                ideal_key = k
                break
        if ideal_key is None:
            raise KeyError(f"Ideal key missing. Found: {sorted(keys)}")

        # Noisy Signal
        noisy_key = None
        for k in ["signal", "signal_noisy", "measurement"]:
            if k in keys:
                noisy_key = k
                break
        # Fallback: if no distinct noisy signal, assume ideal (weird case)
        if noisy_key is None:
            LOGGER.warning("No explicit noisy signal key found. Using ideal as noisy.")
            noisy_key = ideal_key

        labels_key = "labels" if "labels" in keys else None

        return DataKeys(t=t_key, ideal=ideal_key, noisy=noisy_key, labels=labels_key)

    def load_dataset(self) -> None:
        """Load and prepare the dataset for training."""
        data_cfg = self.config["data"]
        data_rel = Path(data_cfg["path"])
        file_path = data_rel if data_rel.is_absolute() else (self.project_root / data_rel)

        if not file_path.exists():
            raise FileNotFoundError(f"Dataset missing at {file_path}")

        archive = np.load(file_path, allow_pickle=True)
        keys = list(archive.files)
        kmap = self._resolve_data_keys(keys)

        t = torch.tensor(archive[kmap.t], dtype=torch.float32).reshape(-1, 1)
        ideal = torch.tensor(archive[kmap.ideal], dtype=torch.float32).reshape(-1, 1)
        noisy = torch.tensor(archive[kmap.noisy], dtype=torch.float32).reshape(-1, 1)

        # Construct noise proxy: |Noisy - Ideal|
        # NOTE: In this synthetic experiment, we utilize the known ground truth ('ideal')
        # to supervise the Falsity channel. In a strictly unsupervised deployment,
        # this would be replaced by a self-supervised consistency metric or
        # an estimated noise baseline.
        noise_proxy = torch.abs(noisy - ideal)

        base = TensorDataset(t, ideal, noise_proxy)

        labels = None
        if kmap.labels is not None:
            raw = np.asarray(archive[kmap.labels]).reshape(-1)
            if raw.shape[0] == len(base):
                labels = torch.tensor(raw, dtype=torch.int64)
            else:
                LOGGER.warning("labels length mismatch: labels=%s dataset=%s; ignoring labels", raw.shape, len(base))

        train_ds, val_ds = self._split_dataset(base, labels=labels)

        bs = int(self.config["training"]["batch_size"])
        num_workers = int(data_cfg.get("num_workers", 0))
        shuffle = bool(data_cfg.get("shuffle", True))

        self.train_loader = DataLoader(train_ds, batch_size=bs, shuffle=shuffle, num_workers=num_workers)
        self.val_loader = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=num_workers)

        LOGGER.info("Loaded dataset: %s", file_path)
        LOGGER.info("Resolved keys: %s", {"t": kmap.t, "ideal": kmap.ideal, "noisy": kmap.noisy, "labels": kmap.labels})
        LOGGER.info("Split: train=%d, val=%d", len(train_ds), len(val_ds))

        if "meta" in keys:
            try:
                meta = archive["meta"].item()
                noise_meta = meta.get("noise", {})
                phys_meta = meta.get("physics", {})
                LOGGER.info("Meta(noise): %s", noise_meta)
                LOGGER.info("Meta(physics): %s", phys_meta)
            except Exception:
                LOGGER.warning("Failed to parse archive['meta'] (kept as-is).")

    def _split_dataset(self, dataset: TensorDataset, labels: Optional[torch.Tensor]) -> Tuple[Subset, Subset]:
        """Split dataset into train and validation sets."""
        data_cfg = self.config.get("data", {})
        val_ratio = float(data_cfg.get("test_split", 0.2))

        n = len(dataset)
        if n < 2:
            raise ValueError("Dataset too small to split.")

        if labels is not None:
            # 0=train, 1=test
            # Ensure labels are compatible
            uniq = set(labels.detach().cpu().numpy().tolist())
            if uniq.issubset({0, 1}):
                train_idx = (labels == 0).nonzero(as_tuple=False).flatten().tolist()
                val_idx = (labels == 1).nonzero(as_tuple=False).flatten().tolist()

                # If valid split
                if len(train_idx) > 0 and len(val_idx) > 0:
                    return Subset(dataset, train_idx), Subset(dataset, val_idx)

                LOGGER.warning("labels-based split is degenerate (one set empty); falling back to random split.")

        # Fallback to random or ratio split
        val_len = max(1, int(round(n * val_ratio)))
        train_len = n - val_len
        perm = torch.randperm(n)
        train_idx = perm[:train_len].tolist()
        val_idx = perm[train_len:].tolist()
        return Subset(dataset, train_idx), Subset(dataset, val_idx)

    def execute(self) -> None:
        """Run the main training loop."""
        if self.train_loader is None or self.val_loader is None:
            raise RuntimeError("Dataset is not loaded. Call load_dataset() first.")

        epochs = int(self.config["training"]["epochs"])

        ckpt_cfg = self.config.get("checkpointing", {})
        base_dir_rel = Path(ckpt_cfg.get("save_dir", "checkpoints"))
        base_dir = base_dir_rel if base_dir_rel.is_absolute() else (self.project_root / base_dir_rel)
        
        # Append seed-specific subdirectory to isolate runs
        save_dir = base_dir / f"seed_{self.seed}"
        
        save_best_only = bool(ckpt_cfg.get("save_best_only", True))
        monitor = str(ckpt_cfg.get("monitor", "val_loss"))

        save_dir.mkdir(parents=True, exist_ok=True)
        (save_dir / "run_config.yaml").write_text(self.config_path.read_text(encoding="utf-8"), encoding="utf-8")

        best_val = float("inf")
        history: Dict[str, list] = {
            "train_loss": [],
            "val_loss": [],
            "lr": [],
            "alpha_first": [],
            "alpha_summary": [],
        }

        LOGGER.info("Training start: epochs=%d | monitor=%s | save_dir=%s", epochs, monitor, save_dir)

        for epoch in range(1, epochs + 1):
            train_loss = self._train_one_epoch(epoch, epochs)
            val_loss = self._validate()

            if self.scheduler is not None:
                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_loss)
                else:
                    self.scheduler.step()

            lr = float(self.optimizer.param_groups[0]["lr"])
            alpha_first = float(self.model.get_logic_parameter())
            alpha_summary = self.model.get_alpha_summary()

            history["train_loss"].append(float(train_loss))
            history["val_loss"].append(float(val_loss))
            history["lr"].append(lr)
            history["alpha_first"].append(alpha_first)
            history["alpha_summary"].append(alpha_summary)

            improved = (not np.isnan(val_loss)) and (val_loss < best_val)
            if improved:
                best_val = val_loss
                torch.save(self.model.state_dict(), save_dir / "best_model.pth")
                if not save_best_only:
                    torch.save(self.model.state_dict(), save_dir / f"model_epoch_{epoch:04d}.pth")

            if epoch % 100 == 0:
                torch.save(self.model.state_dict(), save_dir / "last_model.pth")

            if epoch == 1 or epoch % 50 == 0:
                LOGGER.info(
                    "Epoch %04d | train=%.3e | val=%.3e | lr=%.2e | alpha0=%.3f",
                    epoch, train_loss, val_loss, lr, alpha_first
                )

        np.save(save_dir / "training_history.npy", history, allow_pickle=True)
        LOGGER.info("Training done. Best val=%.3e | saved=%s", best_val, save_dir / "best_model.pth")

    def _train_one_epoch(self, epoch: int, epochs: int) -> float:
        self.model.train()
        total = 0.0
        n_batches = 0

        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch}/{epochs}", leave=False)
        for batch_t, batch_ideal, batch_noise in pbar:
            batch_t = batch_t.to(self.device)
            batch_ideal = batch_ideal.to(self.device)
            batch_noise = batch_noise.to(self.device)

            self.optimizer.zero_grad(set_to_none=True)
            t_pred, f_pred = self.model(batch_t)

            # Loss expects: signal_pred, noise_pred, signal_target, noise_proxy
            # Here signal_target is ideal physics.
            loss, _ = self.criterion(t_pred, f_pred, batch_ideal, batch_noise)

            if not torch.isfinite(loss):
                raise RuntimeError(f"Non-finite loss detected (epoch={epoch}): {loss.detach().cpu().item()}")

            loss.backward()
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            self.optimizer.step()

            total += float(loss.detach().cpu().item())
            n_batches += 1
            pbar.set_postfix({"loss": f"{float(loss.detach().cpu().item()):.2e}"})

        return total / max(1, n_batches)

    def _validate(self) -> float:
        self.model.eval()
        total = 0.0
        n_batches = 0
        with torch.no_grad():
            for batch_t, batch_ideal, batch_noise in self.val_loader:
                batch_t = batch_t.to(self.device)
                batch_ideal = batch_ideal.to(self.device)
                batch_noise = batch_noise.to(self.device)

                t_pred, f_pred = self.model(batch_t)
                loss, _ = self.criterion(t_pred, f_pred, batch_ideal, batch_noise)

                total += float(loss.detach().cpu().item())
                n_batches += 1

        return total / max(1, n_batches)


def main() -> int:
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, required=True, help="Path to YAML config (e.g., configs/mixed_regime.yaml)")
    parser.add_argument("--seed", type=int, default=None, help="Override random seed for reproducibility")
    parser.add_argument("--log-level", type=str, default="INFO", help="DEBUG/INFO/WARNING/ERROR")
    args = parser.parse_args()

    logging.basicConfig(
        level=getattr(logging, args.log_level.upper(), logging.INFO),
        format="%(asctime)s | %(levelname)s | %(name)s | %(message)s",
    )

    cfg_path = Path(args.config).resolve()
    project_root = find_project_root(Path(__file__).resolve())
    if str(project_root) not in sys.path:
        sys.path.append(str(project_root))

    # Pass the CLI seed to the trainer
    trainer = QuantumTrainer(cfg_path, seed=args.seed)
    trainer.load_dataset()
    trainer.execute()
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
